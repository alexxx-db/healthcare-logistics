{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPDM097: Working with geospatial health data\n",
    "\n",
    "Many health service problems are affected by geography.  The first step is often to understand demand from a geospatial perspective.  To do this we can use basic summary statistics, but also make use of Python's extensive mapping and geospatial packages.  For small to medium size geospatial problems you may find this is all that is needed to help your customers/collaborators make a decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this computer practical you will learn how to:**\n",
    "\n",
    "* Use `GeoPandas` for managing and importing geospatial health data\n",
    "* Plot basic and sophisticated maps of health demand and travel times to nearest health delivering facilities to help answer research questions.\n",
    "\n",
    "In this tutorial we will use a health dataset.\n",
    "\n",
    "* **Exeter stroke admissions.**  The the number of stroke unit admissions to the Royal Devon and Exeter hospital by Lower Super Output Area\n",
    "\n",
    "In a geospatial analysis it is sometime useful to bring in additional data to enhance the analysis.  We will use:\n",
    "\n",
    "* **Population estimates by Lower Super Output Areas**\n",
    "* **Indicies of multiple deprevation (IMD) by Lower Super Output Area**.  In particular, we will look at deciles of depreviation which enable us to identify the least and most deprived areas. \n",
    "* **Deterministic Travel time from LSOAs to hospitals**.  These are data taken from GIS software (in this case Routino).\n",
    "\n",
    "> At the end of the notebook there are several **optional** exercises that explore creating more sophisticated inset maps and use of `folium`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "> Please run this notebook with the provided environment `hds_logistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Introduction to GeoPandas\n",
    "\n",
    "`Geopandas` builds on top of `pandas` and extends its functionality to tackle geographic data. \n",
    "\n",
    "> In pandas you work with a `DataFrame`.  In `geopandas` you work with a `GeoDataFrame`.  As these are extensions of a `DataFrame` they behave in a very similar way, but have additional functionality for handling geometry.\n",
    "\n",
    "## Importing Geospatial LSOA data for the South West of England\n",
    "\n",
    "For geospatial analysis you usually work with some form of shape file.  We will use shape data stored in GeoJson format.  This is publically available data for England published by the [ONS](https://opendata.arcgis.com/datasets/fd7e9e6e82584a54b06aae40b8ca6988_0.geojson). In this exercise we will work with a local subset of the data for the South West of England.  \n",
    "\n",
    "Note the way to read the file:\n",
    "\n",
    "```python\n",
    "# include \"zip://\" in the file path as it is a compressed file\n",
    "gpd.read_file(\"zip://./data/devon_cornwall.zip\")\n",
    "```\n",
    "\n",
    "> **Note**: the England file is 1GB+, you will need to wait for it, but it does load fine into geopandas.  The South West dataset is 75mb which is still fairly large so it is compressed. Geopandas can handle compressed data.\n",
    "\n",
    "Shape files and other data files are usually quite large and not very transferable with your analysis files.  It is straightforward to open a data file from a remote repository such as GitHub.  It may take a few seconds to download if it is a big file!  For example, to load the same data directory from its GitHub repo we just need to specify its url:\n",
    "\n",
    "```python\n",
    "url = \"https://raw.githubusercontent.com/health-data-science-OR/healthcare-logistics/master/mapping/data/devon_cornwall.zip\"\n",
    "gpd.read_file(url, crs='EPSG:4326')\n",
    "```\n",
    "### Coordiante Reference Systems,\n",
    "\n",
    "Geographic data has a **crs** (Coordinate Reference System). EPSG:27700 is the crs to use when geography is in BNG (British National Grid Eastings and Northings).  Geopandas handles this automatically for you, but occationally you will need to set it during your analysis.\n",
    "\n",
    "* EPSG:27700 OSGB 1936 / British National Grid -- United Kingdom Ordnance Survey. Co-ordinates are in Eastings (X) and Northings (Y).\n",
    "* EPSG:4326 WGS 84 -- WGS84 - World Geodetic System 1984. Co-ordinates are in Longitude (X) and Latitude (Y).\n",
    "* EPSG:3857 - projection for displaying lat/long as a flat map.  We will use this when adding a `contextily` base map.\n",
    "\n",
    "> The South West data is coded in Lat/Long format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.  Read in a local GeoJson file\n",
    "\n",
    "**Task:**\n",
    "    \n",
    "* read in the geojson shape data from /data/devon_cornwall.zip and assign to a variable with name `south_west`.  The data has Lat/Long coordinates.\n",
    "\n",
    "**Questions:**\n",
    "* What is the the type of `south_west`?\n",
    "* What is shape of `south_west`?\n",
    "* What are the columns in `south_west`?\n",
    "* How do you view the first 5 rows of `south_west`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.a Read in remote data to a GeoDataFrame\n",
    "\n",
    "**Task**\n",
    "* Read shape file data from the provided URL into a `GeoDataFrame` called `remote_sw`\n",
    "\n",
    "**Hints**:\n",
    "* This is the identical data to what we have in `south_west`, but downloaded from a remote source. View the first 5 rows of `remote_sw` to see that it matches the data in `south_west`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you run this it will take some time to download..\n",
    "url = 'https://raw.githubusercontent.com/health-data-science-OR/' \\\n",
    "        + 'healthcare-logistics/master/mapping/data/devon_cornwall.zip'\n",
    "\n",
    "#your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting sub regions\n",
    "\n",
    "Your `GeoDataFrame` contains a number of fields related to LSOA.  The key ones are\n",
    "\n",
    "* LSOA11CD: e.g. E01029722.  This is a unqiue code identifying the LSOA defined in 2011. The first charactor 'E' represents the country in this case **E**ngland.\n",
    "* LSAO11NM: e.g. Stafford 009C.  This is the unique name identifying the LSOA defined in 2011.\n",
    "\n",
    "> We also have a field LSOA11NMW - this is the name in Welsh.\n",
    "\n",
    "The name field is useful for quick filtering of the main dataset down to sub regions.  For example to filter for 'Exeter' we use:\n",
    "\n",
    "```python\n",
    "region = \"Exeter\"\n",
    "exeter = south_west[south_west['LSOA11NM'].str.contains(region)]\n",
    "```\n",
    "\n",
    "# Exercise 2: Filtering sub regions\n",
    "\n",
    "**Task:**\n",
    "\n",
    "* Create four new `GeoDataFrame` objects for \"Exeter\", \"North Devon\", \"Cornwall\" and (the Isles of) \"Scilly\".  \n",
    "* Call the sub regions `exeter`, `north_devon`, `cornwall` and `scilly`, respectively.\n",
    "* Concatenate `cornwall` and `scilly` into a single `GeoDataFrame`, **using the variable name `cornwall`**.\n",
    "* Check the shape of your new objects.\n",
    "* Take a look at the data in each `GeoDataFrame` and confirm your code has worked.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "* Remember a `GeoDataFrame` is an extension of `pandas.DataFrame`.  You can use the same method to **concatenate** each type of object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting maps\n",
    "\n",
    "The basic plotting of a map is done *pandas style* by calling `GeoDataFrame.plot(**kwargs)`.  For example to plot `south_west` use the following code:\n",
    "\n",
    "```python\n",
    "# pandas style plotting \n",
    "ax = south_west.plot(figsize=(12, 9))\n",
    "```\n",
    "\n",
    "> The method returns a matplotlib `axis` object.  This is used to add additional layers and information etc. \n",
    "\n",
    "# Exercise 3: Basic plotting\n",
    "\n",
    "**Task:**\n",
    "* Plot `south_west`, `exeter`, `north_devon` and `cornwall` frames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data representing points of importance and plotting it.\n",
    "\n",
    "Often with health data we need to add health delivering facilities to a map.  For example acute hospitals, community hospitals, GP surgeries, minor injury units, walk in clinics, or outpatient clinics. In the UK, these will usually have a postcode / exact Lat/Long that isn't confidential or sensitive. It is therefore relatively straightforward to add them to a map.  The tricky part is that we need to create the geometry manually.\n",
    "\n",
    "We will work with `./data/sw_acute_hospitals.csv`.  This has four columns: acute (name), postcode and lat, long. \n",
    "\n",
    "> Since version 1.0.0 of `geopandas.read_file()` will return a `pandas.DataFrame` if no geometry is included.  We therefore need a step that creates the geometry and converts to a `GeoDataFrame`.\n",
    "\n",
    "**Steps to load and preprocess the data** \n",
    "1. Load the `DataFrame` from file.  Let's assume the frame has been given the name `sw_acute`\n",
    "2. Manually create the geometry field.  Use the `geopandas.points_from_xy()` method like so:\n",
    "\n",
    "```python\n",
    "# Set geometry (note longitude comes first as GeoPandas expects x/y geometry)\n",
    "sw_acute = gpd.GeoDataFrame(\n",
    "    sw_acute, geometry=gpd.points_from_xy(sw_acute.long, sw_acute.lat), \n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "```\n",
    "\n",
    "Once you have loaded and preprocessed you are ready to plot!  \n",
    "\n",
    "**Steps to plot**:\n",
    "\n",
    "1. Plot the LSOA shapes contained in `south_west` \n",
    "2. Plot the hospitals.  To do this you need to pass in the `axis` object returned in step 1.  Like so:\n",
    "\n",
    "```python\n",
    "sw_acute.plot(ax=ax, edgecolor='k', facecolor='w', markersize=200, \n",
    "              marker='*')\n",
    "```\n",
    "\n",
    "> We have passed in some options here to determine the colouring, size and shape of the points.\n",
    "\n",
    "# Exercise 4: Plotting acute hospitals in the South West.\n",
    "\n",
    "**Task**:\n",
    "* Using `south_west` and the file `./data/sw_acute_hospitals.csv` plot all of the acute hospitals in the south west on a map.\n",
    "* Feel free to experiment with parameters for colour, markersize and style.\n",
    "* (Optional) add a label to the plot using standard Matplotlib.\n",
    "\n",
    "**Hints:**\n",
    "* Your basic result should look like\n",
    "\n",
    "![test](./images/basic_sw_map_points.png)\n",
    "\n",
    "* To add a label to the plot you can use the following code snippet that offsets the 'acute' field name from the point.\n",
    "\n",
    "```python\n",
    "# Add labels\n",
    "for x, y, label in zip(\n",
    "    sw_acute.geometry.x, sw_acute.geometry.y, sw_acute.acute):\n",
    "        ax.annotate(label, xy=(x, y), xytext=(8, 8), textcoords=\"offset points\",\n",
    "                    backgroundcolor=\"w\", fontsize=8)\n",
    "```\n",
    "* If you want to drop the Lat/Long axes then use\n",
    "\n",
    "```python\n",
    "ax.set_axis_off()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising quantitative geospatial data.\n",
    "\n",
    "We will now work with the stroke admissions dataset.  These are patients admitted to Exeter hospital.  Note that these patients may live outside of the 'exeter geographic area'.  \n",
    "\n",
    "It is highly likely that your quantitative data will be stored in a seperate file from your spatial shapes. For example, you would expect that the quantitative data is supplied by an NHS Clinical Commissioning Group (CCG) or a provider organisation such as an NHS Acute Trust.  The spatial shape data would need to be sourced independently for example from the UK's Office of National Statistics (ONS; or equivalent from another country). \n",
    "\n",
    "A key task in geospatial analysis is therefore merging these datasets.  In order to merge two datasets, each dataset needs to have a common naming system for the areas to enable the algorithm to match the corresponding areas across the datasets. For our example this is contained in the field LSOA11NM. The field LSOA11CD is also often used.\n",
    "\n",
    "The basic process for doing this is as follows:\n",
    "\n",
    "1. Load and verify your shape file as `GeoDataFrame`.  Check that this plots as expected.\n",
    "2. Load and verify your quantitative health data.  An option is to do this as a straightforward pandas `DataFrame`\n",
    "3. Use the `GeoDataFrame.merge(data, on, how)` method to combine the fields.  It is easiest to have a key in each dataframe with the same name.\n",
    "\n",
    "**Example merging:**\n",
    "\n",
    "Assume you have a `DataFrame` with name `exeter_strokes` with columns ['LSOA11NM', 'admissions'] and a `GeoDataFrame` named `south_west` containing the shapes.\n",
    "\n",
    "```python\n",
    "gdf_exeter_admit = \\\n",
    "    south_west[['LSOA11CD', 'LSOA11NM', 'geometry']].merge(exeter_strokes, \n",
    "                                                           on='LSOA11NM', \n",
    "                                                           how='inner')\n",
    "\n",
    "```\n",
    "The code listing above linked on the key 'LSOA11NM'. The result is new `GeoDataFrame` with the same number of rows as `exeter_strokes`, the fields 'LSOA11CD', 'LSOA11NM', 'geometry' and 'admissions'.  You get the same number of rows as `exeter_stroke` because the operation was an **inner** join.  As an alternative you could set the parameter `how='outer'`.  An **outer** join would result in the same number of rows as `south_west`.  In this case the 'admissions' field would be `NaN` (not a number aka none or null) for those LSOA's where there were no stroke admissions in Exeter.  \n",
    "\n",
    "Specify which columns you'd like from each of the DataFrames by including the column names in double square brackets. If you'd like all of the columns to be included in the resulting `GeoDataFrame`, then just write the variable name (without double brackets following). For the example above the resulting merge will take three columns from `south_west` and all the columns from `exeter_strokes`. Always remember to include the common column that the merge is joining on in the selection.\n",
    "\n",
    "**Example plotting**\n",
    "\n",
    "Now that you have the merged dataset you can plot it. The following code listing outputs a plot where LSOAs are coloured depending on the number of admissions.\n",
    "\n",
    "```python\n",
    "ax = gdf_exeter_admit.plot(column='admissions', figsize=(12,6),  \n",
    "                           legend=True)\n",
    "```\n",
    "\n",
    "The code listing above uses a continuous scale.  Sometimes it is useful to **bin** the values into ranges.  Using the `scheme='` parameter switches to automatically sized bins.  For example using the Quantiles scheme:\n",
    "\n",
    "```python\n",
    "ax = gdf_exeter_admit.plot(column='admissions',scheme='Quantiles', \n",
    "                           figsize=(12,6),  \n",
    "                           legend=True)\n",
    "```\n",
    "\n",
    "You can try a few options (see help for an exhaustive list)\n",
    "* Quantiles - bins split by the quantiles\n",
    "* EqualIntervals - bins into equal sizes\n",
    "* StdMean - bins split by the number of standard deviations a variable is from the mean.\n",
    "\n",
    "You might also find that the default colour map (the shading of the areas) is not to your liking or is not clear or helpful for a decision maker.  To can change this using the `cmap` parameter.  A list of options is [here](https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html).  But easy ones to remember are 'autumn', 'winter', 'spring', 'summer'.\n",
    "\n",
    "```python\n",
    "ax = gdf_exeter_admit.plot(column='admissions',scheme='Quantiles', \n",
    "                           figsize=(12,6), cmap='autumn',\n",
    "                           legend=True)\n",
    "```\n",
    "\n",
    "# Exercise 5: Bringing in the admissions data\n",
    "\n",
    "**Task:**\n",
    "* Load the stroke admissions dataset and merge it with `south_west` to create a new `GeoDataFrame`.  It it recommended you call the dataframe `gdf_exeter_admit`.\n",
    "* The data are stored in `data/exeter_stroke_admissions.csv`\n",
    "* Plot the admissions data\n",
    "* Add in a marker for the Royal Devon and Exeter hospital\n",
    "\n",
    "**Questions** \n",
    "* Test out the default, Quantiles, EqualIntervals and StdMean schemes.  Which do you prefer and why?\n",
    "* Test out different colour maps.  Which do you prefer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalising geospatial health data \n",
    "\n",
    "A weakness of the analysis we have conducted so far is that the population in each LSOA varies between 1000 and 3000.  At the extremes this means that our 'high and low incidence' LSOAs might just be a function of population size.  At the very least we have a source of variance in the analysis that is potentially counfounding our interpretation.\n",
    "\n",
    "To get a handle on this you will now use estimates of the population size in each LSOA to normalise the data.  You will calculate the number of admission per 1000 of population.  This is a simple calculation.  If a LSOA has a population of 1500 and there were 50 stroke admissions then the rate per 1000 of population is 50 / (1500 / 1000) = 33.33\n",
    "\n",
    "In the UK, you can again get estimates of population size from the Office of National Statistics ![(ONS)]() geoportal. The file `mid-2017-lsoa-pop-estimates.zip` contains these data broken down by age band (this is a compressed .csv file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Comparing absolute admissions with rate per 1000\n",
    "\n",
    "**Task:**\n",
    "* Read in `mid-2017-lsoa-pop-estimates.zip` (url provided below) to a `DataFrame`and merge the 'All Ages' field  (total count of population) with your `GeoDataFrame`.\n",
    "* Calculate the rate per 1000 of population. **Call this new column `admits_per_1k`**\n",
    "* Create a side by side (or above and below) plot of the rate per 1k of population and the absolute number of admissions\n",
    "* Use your preferred colour map and scheme to display the data.\n",
    "\n",
    "**Questions:**\n",
    "* What are the differences between the two approaches to visualisation?\n",
    "* Are there any LSOA's that have particularly high admission rates per 1000 of pop?\n",
    "\n",
    "**Hints**\n",
    "* In matplotlib you can create **subplots** that allow you to plot multiple maps int the same figure.  For example the code:\n",
    "\n",
    "```python\n",
    "fig, ax = plt.subplots(2, 1, sharex=True, figsize=(15,12))\n",
    "```\n",
    "\n",
    "creates 2 rows and 1 column with a shared x axis.  The variable `ax` is a numpy array of the 2 axes (i.e. it has 2 elements referencing the two subplots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "url = 'https://raw.githubusercontent.com/health-data-science-OR/' \\\n",
    "    + 'healthcare-logistics/master/mapping/data/mid-2017-lsoa-pop-estimates.zip'\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicies of Multiple Deprivation (IMD)\n",
    "\n",
    "An Index of Multiple Deprivation (IMD) is an overall measure of multiple deprivation experienced by people living in an area and is calculated for every Lower layer Super Output Area (LSOA) in England. The IMD can be used to rank every LSOA in England according to their relative level of deprivation.  IMD for a LSOA is often viewed as a **decile** (1-10 where 1 is the top 10% of deprived areas in England).  When analysing health service demand and equitable access, IMD can be a useful measure to explore geographically. \n",
    "\n",
    "> IMD updates are published periodically.  There were updates in 2010, 2015 and 2019.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7: Plotting deprivation\n",
    "\n",
    "**Task:**\n",
    "* Read `Indices_of_Multiple_Deprivation_(IMD)_2019.zip` (URL provided below) into a `DataFrame` and merge the field `IMD_Decile` with your `GeoDataFrame` \n",
    "* Create a side by side (or above and below) plot of the rate per 1k of population and the deprivation\n",
    "* Try different colour maps and schemes to display the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "url = 'https://raw.githubusercontent.com/health-data-science-OR/' \\\n",
    "        + 'healthcare-logistics/master/mapping/data/' \\\n",
    "            + 'Indices_of_Multiple_Deprivation_(IMD)_2019.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a base using contextily\n",
    "\n",
    "You can add a base map using contextily.  We have already imported the package:\n",
    "\n",
    "```python\n",
    "import contextily as ctx\n",
    "```\n",
    "\n",
    "> To work with contextily at the moment it is best to convert your data into a flat projection i.e. EPSG:3857\n",
    "\n",
    "Contextily downloads tile maps from internet sources (note this means that there may be a short delay while it downloads).  For example to add an openstreetmap base tile:\n",
    "    \n",
    "```python\n",
    "\n",
    "# convert your data to a flat projection\n",
    "gdf_exeter_admit = gdf_exeter_admit.to_crs(epsg=3857)\n",
    "sw_acute = sw_acute.to_crs(epsg=3857)\n",
    "\n",
    "# create map of IMD deciles\n",
    "ax = gdf_exeter_admit.plot(column='IMD_Decile',  cmap='autumn',\n",
    "                       legend=True, figsize=(15,9))\n",
    "\n",
    "#add base map using contextily\n",
    "ctx.add_basemap(ax, \n",
    "                #set to use open street map\n",
    "                source=ctx.providers.OpenStreetMap.Mapnik,\n",
    "                #zoom level \n",
    "                zoom=10)\n",
    "```\n",
    "\n",
    "Example ctx.providers are:\n",
    "\n",
    "* \"OpenStreetMap.Mapnik\"\n",
    "* \"CartoDB.Positron\"\n",
    "* \"CartoDB.Voyager\"\n",
    "\n",
    "you can see all provider by running\n",
    "\n",
    "```python\n",
    "ctx.providers\n",
    "```\n",
    "\n",
    "# Exercise 8\n",
    "\n",
    "**Task:**\n",
    "* Run the code below to add a contextily base map\n",
    "* Try different `source` parameters in `add_basemap`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the exeter admissions dataset to EPSG=3857\n",
    "gdf_exeter_admit_flat = gdf_exeter_admit.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sw acute hospital data to EPSG=3857\n",
    "sw_acute_flat = sw_acute.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of IMD deciles\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "gdf_exeter_admit_flat.plot(column='IMD_Decile',\n",
    "                          cmap='inferno_r',\n",
    "                          # slight transparency to see base map\n",
    "                          alpha = 0.70, ax=ax, \n",
    "                          # include colour map legend\n",
    "                          legend=True,\n",
    "                          # Adjust size of colourmap key, and add label\n",
    "                          legend_kwds={'shrink':0.4, \n",
    "                                       'orientation': \"vertical\",\n",
    "                                       'label':'IMD_Decile'})\n",
    "\n",
    "\n",
    "#plot the RDE and only\n",
    "sw_acute_flat.loc[sw_acute['acute'] == 'RDE'].plot(ax=ax, edgecolor='k', \n",
    "                                                   facecolor='r', \n",
    "                                                   markersize=200, \n",
    "                                                   marker='*')\n",
    "\n",
    "#### CODE UPDATED 2024. all stamen tiles deprecated.\n",
    "# base map using contextily\n",
    "ctx.add_basemap(ax,\n",
    "                source=ctx.providers.OpenStreetMap.Mapnik,\n",
    "                zoom=10)\n",
    "#####\n",
    "\n",
    "ax.set_axis_off()\n",
    "ax.set_title('IMD Decile by LSOA')\n",
    "# Adjust for printing\n",
    "ax.margins(0)\n",
    "plt.subplots_adjust(left=0.01, right=1.0, bottom=0.0, top=1.0)\n",
    "ax.apply_aspect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with travel times and distances\n",
    "\n",
    "A number of decisions in health are influenced by balancing quality, cost and equitable access to health services.  Planners often use travel time (or distance) to understand the implications of different configurations of their system on fairness.  For example, the combination of outpatient clinics open on a given days, centralisation of specialist services or the closure of a facility.  A map can be a useful to support decision makers understanding of if certain areas 'travel burden' is greater than others.  This might be enhanced for example, by considering deprivation and attempting to ensure that the most deprived areas are not unduly disadvantaged by service changes.\n",
    "\n",
    "As a simple example of exploring travel times to health facilities recall our example with all of the acute hospitals in the south west. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop isles of scily as it skews travel times...\n",
    "south_west2 = south_west[~south_west['LSOA11NM'].str.contains('Scilly')]\n",
    "\n",
    "# plot\n",
    "ax = south_west2.plot(figsize=(8, 8))\n",
    "\n",
    "# add markers for hospitals\n",
    "ax = sw_acute.plot(ax=ax, edgecolor='k', facecolor='y', markersize=500, \n",
    "              marker='*')\n",
    "\n",
    "# optionally add in labels\n",
    "for x, y, label in zip(\n",
    "    sw_acute.geometry.x, sw_acute.geometry.y, sw_acute.acute):\n",
    "        ax.annotate(label, xy=(x, y), xytext=(8, 8), textcoords=\"offset points\",\n",
    "                    backgroundcolor=\"w\", fontsize=8)\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9: Preprocessing and mapping travel times.\n",
    "\n",
    "You are provided with deterministic estimates of travel times in minutes between all the centroid of all 32,843 LSOAs and hospitals in England in the file 'travel_matrix_minutes.zip' (url provided below).  You can think of this table as a 'lookup'.  The rows list LSOA and the columns list postcodes (hospital) locations. \n",
    "\n",
    "**Task:**\n",
    "* Load the national travel time matrix into a `DataFrame`\n",
    "* For the LSOAs and hospitals in the south west find the closest hospital (shortest travel time to a south west hospital).\n",
    "* Revise the above plot to create a geospatial view of travel time to hospital.\n",
    "\n",
    "**Hints**:\n",
    "* The travel time data is a compressed .csv file.  Pandas can handle zip files automatically.  Just called `pd.read_csv(url)`\n",
    "* To help, you can work with a 'trimmed' down or 'local' version of the travel matrix relating only to the south west hospitals.  To do this you can use some standard `DataFrame` operations.  Call this variabe `local_travel_matrix`. Remember that you have `DataFrame` called `sw_acute` that contains a column of their postcodes.  \n",
    "* Once you have limited to the hospitals in the south west you can find the minimum travel time using standard pandas (just remember that you are working with columns so axis=1).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here...\n",
    "url = 'https://raw.githubusercontent.com/health-data-science-OR' \\\n",
    "    + '/healthcare-logistics/master/mapping/data/travel_matrix_minutes.zip'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating travel time to multiple health delivering facilities\n",
    "\n",
    "It is common to use the following approaches to assess travel time to health delivery facilities\n",
    "\n",
    "* Average travel time\n",
    "* Weighted average travel time (i.e. weighted by the number of cases in each LSOA).\n",
    "* Maximum or a percentile (e.g. 95th) of travel time \n",
    "* Proportion of demand within x minutes \n",
    "\n",
    "# Exercise 10\n",
    "\n",
    "**Task**:\n",
    "* Use the function `generate_synthetic_demand` (given below) to generate some demand data.\n",
    "* By extending the code below calculate the average, demand weighted average, maximum and 95th percentile of car travel times to each hospital\n",
    "* Repeat the analysis but limit it to three hospitals with postcodes 'EX2 5DW', 'EX31 4JB', 'TR1 3LQ'\n",
    "* Optional: display the results in a well presented chart or table.\n",
    "\n",
    "**Hints**:\n",
    "* A fast way to find a hosptial travel time average, maximum value or percentile is to used the `DataFrame.groupby()` method.  \n",
    "\n",
    "```python\n",
    "lsoa_demand.groupby(by='nearest_facility')['mins_to_nearest_hospital'].mean()\n",
    "```\n",
    "\n",
    "* To calculate a weighted average travel time is a bit more involved in standard pandas.  It works best if you use numpy's `average` function that accepts weights.  To implement this with a lambda expression you use the following code:\n",
    "\n",
    "```python\n",
    "lsoa_demand.groupby(by='nearest_facility').apply(lambda x: \n",
    "                                                 np.average(\n",
    "                                                     x.mins_to_nearest_hospital, \n",
    "                                                     weights=x.cases))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_demand(lsoa_frame, random_seed=42):\n",
    "    # create random num generator\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    \n",
    "    # code to generate synthetic data\n",
    "    lsoa_demand = lsoa_frame['LSOA11NM'].to_frame()\n",
    "    lsoa_demand['cases'] = rng.randint(0, 20, size=len(lsoa_demand))\n",
    "    \n",
    "    return lsoa_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa_demand = generate_synthetic_demand(local_travel_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa_demand.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa_demand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# **Optional additional content**\n",
    "## To work through in your own time\n",
    "\n",
    "The following additional content has been provided for further study.\n",
    "\n",
    "* Adding an inset map to zoom in on a specific area\n",
    "* Using folium to create an interactive map.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Adding an inset map to zoom in on a specific area\n",
    "\n",
    "A limitation of your stroke admissions map is that the areas with higher density have smaller LSOA shapes.  In particular it is very difficult to see the detail in Exeter.  One way to deal with varying size in a static map image is to create a second 'close up' map of Exeter as a matplotlib inset of your map.  You can think of this as a figure within a figure.  The example we will code is below:\n",
    "![INSERT IMAGE](images/insert_image.png)\n",
    "\n",
    "## Step 1: Filter for admissions from Exeter LSOAs\n",
    "To build our insert map for admissions per 1k of population in Exeter we first need to limit our `GeoDataFrame` to data only containing Exeter LOSAs. There are a couple of way to achieve it, but a simple approach is to filter by 'LSOA11NM' as you learnt eariler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new GeoDataFrame containing only exeter LSAOs\n",
    "region = \"Exeter\"\n",
    "mask = gdf_exeter_admit['LSOA11NM'].str.contains(region)\n",
    "exeter_city_rate = gdf_exeter_admit[mask]\n",
    "exeter_city_rate.plot(figsize=(12,6), column='admits_per_1k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Remembering that the shading needs to be consistent across the main map and its inset\n",
    "\n",
    "Remember that the inset map is a close-up of an area in your main map.  It therefore needs to have consistent colouring for admission numbers.  To achieve this you should make use of the `'userdefined'` scheme.  This allows you to pass a list of user defined bins as well as their labels. The following code demonstrates how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_to_labels(bins, insert_one_as_min=True):\n",
    "    '''\n",
    "    Helper function that creates a list of labels\n",
    "    for bins presented in a GeoDataFrame plot.\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    bins - list\n",
    "        List of floats to group data\n",
    "        \n",
    "    insert_one_as_min - bool, optional (default=True)\n",
    "        Used if you are only including LSOAs that have\n",
    "        at least 1 admission.  Inserts a minimum of 1.\n",
    "    '''\n",
    "    if insert_one_as_min:\n",
    "        bins = bins.copy()\n",
    "        bins.insert(0, 1)\n",
    "    return [str(bins[i]) + '-' + str(bins[i+1]) for i in range(0, len(bins)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "bins = [2, 10, 15, 20]\n",
    "print(bins_to_labels(bins))\n",
    "\n",
    "print(bins_to_labels(bins, insert_one_as_min=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userdefined scheme example limited to Exeter\n",
    "bins = [5, 10, 15, 20]\n",
    "bin_labels = bins_to_labels(bins)\n",
    "\n",
    "\n",
    "# note the scheme = 'userdefined' and \n",
    "# bins are passed via classification_kwds\n",
    "ax = exeter_city_rate.plot(column='admits_per_1k',\n",
    "                           scheme='userdefined', \n",
    "                           cmap='Spectral',\n",
    "                           figsize=(12,9),\n",
    "                           legend=True, \n",
    "                           classification_kwds={'bins': bins},\n",
    "                           legend_kwds={'bbox_to_anchor':(1.2, 1.05),\n",
    "                                        'fontsize':16,'frameon':False,\n",
    "                                        'labels':bin_labels})\n",
    "ax.set_title(\"Exeter City\")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Creating an inset map\n",
    "\n",
    "Matplotlib makes this relatively straight forward.  The inset map API has changed recently and I recommend using the new approach below as the old method will be deprecated in future releases.  \n",
    "\n",
    "The basic logic requires you to create a map and then use `Axes.inset_axes` to create a the inset axis within the main axis.  Full documentation and links to other examples can be found in the [main documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.inset_axes.html#matplotlib.axes.Axes.inset_axes)\n",
    "\n",
    "It is alos possible to add \"zoom lines\" from the main map to the inset.  To do this you need to use the `Axis.indicate_inset_zoom` method.\n",
    " \n",
    "# Optional Exercise 1\n",
    "The code below generates an inset map of Exeter and includes explanation comments.\n",
    "\n",
    "**Task**:\n",
    "* Run the code below and explore the different parameters to see how it affects the map.\n",
    "\n",
    "**Hints**\n",
    "* Maybe copy-paste the code so you still have the original!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup custom bins - note it is a good idea to know what the min/max \n",
    "# of demand per LSOA are.\n",
    "bins = [5, 10, 15, 20, 25, 30]\n",
    "bin_labels = bins_to_labels(bins)\n",
    "\n",
    "cmap = 'viridis'\n",
    "\n",
    "# create figure and main axes objects\n",
    "fig, ax1 = plt.subplots(figsize=(12,12))\n",
    "\n",
    "# plot data (excluding the outlier)\n",
    "ax1 = gdf_exeter_admit.plot(column='admits_per_1k',scheme='userdefined', \n",
    "                            cmap=cmap,\n",
    "                            legend=True, \n",
    "                            classification_kwds={'bins': bins},\n",
    "                            legend_kwds={'bbox_to_anchor':(0.85, 0.97),\n",
    "                                        'fontsize':14,'frameon':False,\n",
    "                                        'labels':bin_labels,\n",
    "                                        'title':'RD&E stroke admissions'\n",
    "                                                +'\\nper 1000 of population',\n",
    "                                        'title_fontsize':14},\n",
    "                             ax=ax1)\n",
    "\n",
    "\n",
    "#### UPDATED code for 2024. New simpler inset API\n",
    "# create the inset\n",
    "# set the lower left x, y location and relative size of the bounding box\n",
    "# note these are in fractional units.\n",
    "ax2 = ax1.inset_axes([0.025,0.5,0.45,0.45])\n",
    "\n",
    "#####\n",
    "\n",
    "#plot the exeter LSOA inset\n",
    "ax2 = exeter_city_rate.plot(column='admits_per_1k',\n",
    "                           scheme='userdefined', \n",
    "                           cmap=cmap,\n",
    "                           legend=False, \n",
    "                           classification_kwds={'bins': bins},\n",
    "                           ax=ax2)\n",
    "\n",
    "\n",
    "# manual text within inset\n",
    "ax2.text(-3.575, 50.755,'Exeter detail', fontsize='large')\n",
    "\n",
    "\n",
    "# plot the RDE and only\n",
    "ax2 = sw_acute.loc[sw_acute['acute'] == 'RDE'].plot(ax=ax2, edgecolor='k', \n",
    "                                                   facecolor='r', \n",
    "                                                   markersize=200, \n",
    "                                                   marker='*')\n",
    "\n",
    "# formatting tweaks...\n",
    "\n",
    "# align legend left\n",
    "leg = ax1.get_legend()\n",
    "leg._legend_box.align = \"left\"\n",
    "\n",
    "# set axis 1 limits to provide enough space for exeter\n",
    "# this might take a bit of trial and error\n",
    "ax1.set_ylim(50.5, 51.6)\n",
    "ax1.set_xlim(-4.5, -2.75)\n",
    "\n",
    "# hide axis tick marks\n",
    "ax2.tick_params(axis=u'both', which=u'both',length=0)\n",
    "\n",
    "# hide axis lat long labels, but keep bounding box\n",
    "ax2.set_xticklabels([])\n",
    "ax2.set_yticklabels([])\n",
    "\n",
    "# #### UPDATED CODE 2024 - new interface\n",
    "# this draw a box around the area where extra detail is needed and\n",
    "# 'zoom out' lines to the detail.\n",
    "# this is optional and the chart might look better without it.\n",
    "# ls = line style '-' for solid, '--' for dashed\n",
    "# ec = edge colour\n",
    "# fc = face colour \n",
    "ax1.indicate_inset_zoom(ax2, edgecolor=\"black\", ls='--', ec='black', fc=None)\n",
    "# ####\n",
    "\n",
    "# hide the box and axis labels\n",
    "ax1.set_axis_off()\n",
    "\n",
    "fig.savefig('images/insert_image.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Using Folium to create interactive plots\n",
    "\n",
    "One of the limitations of the geospatial analysis we have done so far is that we must manually drill down to find out more information (other fields) about a LSOA.  When viewing all LSOAs, it is difficult to see the LSOAs in Exeter itself.  This is due to population density - the higher density areas are smaller to maintain the 1000-3000 population of a LSOA.\n",
    "\n",
    "Folium and Choropleth allow us to create an interactive map where we can both include additional information in a 'tooltip' and control the level of zoom on a map.  \n",
    "\n",
    "## Creating an displaying a Folium map\n",
    "\n",
    "Create a folium base map as follows:\n",
    "\n",
    "```python\n",
    "#create the map object\n",
    "stroke_map = folium.Map(location=[50.71671, -3.50668], zoom_start=9, \n",
    "                        tiles='cartodbpositron')\n",
    "\n",
    "#display the map in the Jupyter notebook\n",
    "stroke_map\n",
    "```\n",
    "\n",
    "The location here is in Lat and Long coordinates (these are the Royal Devon and Exeter Hospital).  They are used to centre the map. The `zoom_start` parameter might take a bit of tweaking to optimise for your application - the higher the number the higher the zoom.  `tiles` is a `str` field where you can specifiy the style of the map.  The following are built into folium\n",
    "\n",
    "* “OpenStreetMap”\n",
    "* “Mapbox Bright” (Limited levels of zoom for free tiles)\n",
    "* “Mapbox Control Room” (Limited levels of zoom for free tiles)\n",
    "* “Cloudmade” (Must pass API key)\n",
    "* “Mapbox” (Must pass API key)\n",
    "* “CartoDB” (positron and dark_matter)\n",
    "\n",
    "A useful trick is to add a number of Tile layers to the map that can be changed interactively.  \n",
    "\n",
    "```python\n",
    "#add some different background layers\n",
    "tiles = ['cartodbpositron', 'cartodbdark_matter', 'openstreetmap']\n",
    "for tile in tiles:\n",
    "    folium.TileLayer(tile).add_to(stroke_map)\n",
    "\n",
    "#add layer control to map\n",
    "folium.LayerControl().add_to(stroke_map)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Exercise 2: A basic folium map\n",
    "\n",
    "**Task:**\n",
    "\n",
    "* Using folium create a base map\n",
    "* centre the map on the Royal Devon and Exeter Hospital: Lat, Long: 50.71671, -3.50668\n",
    "* Add in number of tile layers of your choosing.\n",
    "\n",
    "**Hints**:\n",
    "* In the resulting map cell you will see the layer control in the top right hand corner.  Use it to select the different background tiles you have included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising LSOA shape in folium\n",
    "\n",
    "To visualise shape in folium we will use **Choropleth**.  This provides an easy to use interface for adding shapes to a map.\n",
    "\n",
    "The code listing below demonstrates basic usage.\n",
    "\n",
    "# Optional Exercise 3\n",
    "\n",
    "**Task**\n",
    "* run the code below to add a Choropleth map to your base map.  \n",
    "* explore the effect of changing the parameters e.g. displaying different data fields\n",
    "\n",
    "**Hints**:\n",
    "* Other `fill_color` values include ‘YlGnBu’, 'BuPu’,'OrRd’, 'RdPu’.  The colormap options from matplotlib are not available here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create base map\n",
    "stroke_map = folium.Map(location=[50.71671, -3.50668], zoom_start=9, \n",
    "                        tiles='cartodbpositron')\n",
    "\n",
    "#### Updated code 2024\n",
    "# add some different background layers\n",
    "tiles = ['cartodbpositron', 'cartodbdark_matter', 'openstreetmap']\n",
    "####\n",
    "\n",
    "for tile in tiles:\n",
    "    folium.TileLayer(tile).add_to(stroke_map)\n",
    "\n",
    "# filter data to display\n",
    "fields = ['LSOA11NM', 'admissions', 'admits_per_1k', 'IMD_Decile']\n",
    "lsoa_tia = gdf_exeter_admit[fields]\n",
    "\n",
    "# field to color; 0 = LSOA11NM; 1 = 'admissions' etc.\n",
    "field_index = 3\n",
    "\n",
    "# create and add choropleth map\n",
    "choropleth = folium.Choropleth(\n",
    "    # pass the GeoDataFrame\n",
    "    geo_data=gdf_exeter_admit,\n",
    "    # Data for overlaying\n",
    "    data=lsoa_tia,\n",
    "    #c olumns = [key, field to plot]\n",
    "    columns=['LSOA11NM', fields[field_index]],\n",
    "    key_on='feature.properties.LSOA11NM',\n",
    "    # choose the fill colour\n",
    "    fill_color='OrRd',\n",
    "    # set the legent name\n",
    "    legend_name=fields[field_index],\n",
    "    # highlight the LSOA shape when mouse pointer enters it\n",
    "    highlight=True,\n",
    "    smooth_factor=0).add_to(stroke_map)    \n",
    "    \n",
    "# add layer control to map - make sure you do this after adding choropleth map\n",
    "folium.LayerControl().add_to(stroke_map)\n",
    "\n",
    "stroke_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding tooltips in folium\n",
    "\n",
    "A neat interactive feature of folium is the ability to add a tooltip.  This can display additional information about a lower super output area when the mouse pointer enters its boundary.\n",
    "\n",
    "For example, to add all of our information so far as a tooltip you need to add the following to our previous folium code.\n",
    "\n",
    "```python\n",
    "# Display Region Label\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['LSOA11NM', 'admissions', 'admits_per_1k', 'IMD_Decile'], labels=True)\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Exercise 4:\n",
    "\n",
    "**Task**:\n",
    "* Add a tooltip displaying 'LSOA11NM', 'admissions', 'admits_per_1k',  'IMD_Decile' to your folium map.\n",
    "* run your code and verify that it has worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
